{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tqdm\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "import IPython.display as i_disn\n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "mlp.rc(\"xtick\",labelsize=12)\n",
    "mlp.rc(\"ytick\",labelsize=12)\n",
    "mlp.rc(\"axes\",labelsize=14)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"X_train_features.pkl\",\"rb\") as file:\n",
    "    X_train_features = pickle.load(file)\n",
    "    \n",
    "with open(r\"X_test_features.pkl\",\"rb\") as file:\n",
    "    X_test_features = pickle.load(file)\n",
    "    \n",
    "with open(r\"X_val_features.pkl\",\"rb\") as file:\n",
    "    X_val_features = pickle.load(file)\n",
    "\n",
    "with open(r\"y_train.pkl\",\"rb\") as file:\n",
    "    y_train = pickle.load(file)\n",
    "\n",
    "with open(r\"y_test.pkl\",\"rb\") as file:\n",
    "    y_test = pickle.load(file)\n",
    "\n",
    "with open(r\"y_val.pkl\",\"rb\") as file:\n",
    "    y_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training data: \", X_train_features.shape)\n",
    "print(\"Shape of test data: \", X_test_features.shape)\n",
    "print(\"Shape of validation data: \", X_val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(X_val_features[0].reshape(257, 69), x_axis='time', y_axis='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution, enable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "# enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(features):\n",
    "    scaled = []\n",
    "    min_max_values = []\n",
    "    for f in features:\n",
    "        min_val = np.min(f)\n",
    "        max_val = np.max(f)\n",
    "        f_normalized = (f - min_val) / (max_val - min_val)\n",
    "        min_max_values.append((min_val,max_val))\n",
    "        scaled.append(f_normalized)\n",
    "    return np.array(scaled),np.array(min_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features, X_train_min_max  = MinMaxScaler(X_train_features)\n",
    "X_val_features , X_val_min_max = MinMaxScaler(X_val_features)\n",
    "X_test_features , X_test_min_max = MinMaxScaler(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training data: \", X_train_features.shape)\n",
    "print(\"Shape of test data: \", X_test_features.shape)\n",
    "print(\"Shape of validation data: \", X_val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  X_train_features.reshape(len(X_train_features),np.prod(X_train_features.shape[1:]))\n",
    "X_test = X_test_features.reshape(len(X_test_features),np.prod(X_test_features.shape[1:]))\n",
    "X_val = X_val_features.reshape(len(X_val_features),np.prod(X_val_features.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training data: \", X_train.shape)\n",
    "print(\"Shape of test data: \", X_test.shape)\n",
    "print(\"Shape of validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_dim = X_train.shape[1]\n",
    "latent_dim = 3  # Size of the latent space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# x = Dense(2048, activation='relu')(inputs)\n",
    "x = Dense(1024, activation='relu')(inputs)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch_size = K.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(256, activation='relu')(decoder_inputs)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(2048, activation='relu')(x)\n",
    "outputs = Dense(17733, activation='sigmoid')(x)\n",
    "\n",
    "# Define the encoder and decoder models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_inputs, outputs, name='decoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see encoder summary\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see decoder summary\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for VAE\n",
    "def vae_loss(inputs, x_decoded_mean):\n",
    "    recon_loss = original_dim * binary_crossentropy(inputs, x_decoded_mean)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(recon_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "dense_vae = Model(inputs, outputs, name='vae')\n",
    "dense_vae.compile(optimizer='adam', loss=vae_loss)\n",
    "dense_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestLossCallback(Callback):\n",
    "#     def __init__(self, test_data):\n",
    "#         self.test_data = test_data\n",
    "#         self.test_losses = []\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         test_loss = self.model.evaluate(self.test_data, self.test_data, verbose=0)\n",
    "#         print(f\"\\nTest Loss after Epoch {epoch + 1}: {test_loss}\")\n",
    "#         self.test_losses.append(test_loss)\n",
    "\n",
    "# test_loss_callback = TestLossCallback(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train the VAE\n",
    "\n",
    "# dense_vae_history = dense_vae.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_val, X_val),callbacks=[test_loss_callback])\n",
    "\n",
    "#  Train the VAE\n",
    "\n",
    "dense_vae_history = dense_vae.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(dense_vae_history.history[\"loss\"])\n",
    "plt.plot(dense_vae_history.history[\"val_loss\"])\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss plot for Variational AutoEncoder (with MLP)\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss = dense_vae.evaluate(X_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss: 7673.7411 - val_loss: 7667.3369  7692.695394226507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(7673.7411, 7667.3369, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_train)[0]\n",
    "y_train = [int(y) for y in y_train]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_train, s=3**2,cmap='viridis',alpha=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_space = encoder.predict(X_val)[0]\n",
    "y_val = [int(y) for y in y_val]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "scatter = ax.scatter(latent_space[:, 0], latent_space[:, 1], latent_space[:, 2], c=y_val, s=3**2, cmap='viridis', alpha=1)\n",
    "plt.colorbar(scatter)\n",
    "ax.set_xlabel('Latent Variable 1')\n",
    "ax.set_ylabel('Latent Variable 2')\n",
    "ax.set_zlabel('Latent Variable 3')\n",
    "ax.set_title('3D Latent Space Visualization')\n",
    "\n",
    "# Use `%matplotlib notebook` or `%matplotlib widget` in Jupyter Notebook/Lab for interactive plot\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_val)[0]\n",
    "y_val = [int(y) for y in y_val]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_val, s=3**2,cmap='viridis',alpha=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_test)[0]\n",
    "y_test = [int(y) for y in y_test]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_test, s=3**2,cmap='viridis',alpha=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-11-15 14:06:58.386379: W tensorflow/c/c_api.cc:305] Operation '{name:'loss/mul' id:342 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/decoder_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
    "22840/22840 [==============================] - 64s 3ms/sample - loss: 9949928.5254 - val_loss: 8427.6236\n",
    "Epoch 2/100\n",
    "22840/22840 [==============================] - 62s 3ms/sample - loss: 8685.8543 - val_loss: 8569.1816\n",
    "Epoch 3/100\n",
    "22840/22840 [==============================] - 61s 3ms/sample - loss: 8522.9825 - val_loss: 8377.5673\n",
    "Epoch 4/100\n",
    "22840/22840 [==============================] - 61s 3ms/sample - loss: 8506.5232 - val_loss: 8205.4903\n",
    "Epoch 5/100\n",
    "22840/22840 [==============================] - 61s 3ms/sample - loss: 8261.0748 - val_loss: 8104.8371\n",
    "Epoch 6/100\n",
    "22840/22840 [==============================] - 204s 9ms/sample - loss: 12601.6746 - val_loss: 9356.3297\n",
    "Epoch 7/100\n",
    "22840/22840 [==============================] - 151s 7ms/sample - loss: 17122.5691 - val_loss: 10473.3295\n",
    "Epoch 8/100\n",
    "22840/22840 [==============================] - 95s 4ms/sample - loss: 9971.8597 - val_loss: 9464.1363\n",
    "Epoch 9/100\n",
    "22840/22840 [==============================] - 123s 5ms/sample - loss: 9107.4455 - val_loss: 8522.2567\n",
    "Epoch 10/100\n",
    "22840/22840 [==============================] - 61s 3ms/sample - loss: 11377.3423 - val_loss: 11114.9137\n",
    "Epoch 11/100\n",
    "22840/22840 [==============================] - 62s 3ms/sample - loss: 11209.2646 - val_loss: 10870.3877\n",
    "Epoch 12/100\n",
    "22840/22840 [==============================] - 62s 3ms/sample - loss: 10961.6752 - val_loss: 10756.3944\n",
    "Epoch 13/100\n",
    "22840/22840 [==============================] - 61s 3ms/sample - loss: 10430.8617 - val_loss: 10006.0978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize reconstructed samples\n",
    "\n",
    "decoded_stft = dense_vae.predict(X_test)\n",
    "# decoded_stft = MinMaxUnScaler(dense_vae.predict(X_val),X_val_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decoded_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stft = decoded_stft.reshape(len(decoded_stft),257,69,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxUnScaler(features, min_max_values):\n",
    "    unscaled = []\n",
    "    for f,min_max in zip(features,min_max_values):\n",
    "        f = f.reshape(257,69)\n",
    "        unscaled_feature = (f * (min_max[1] - min_max[0])) + min_max[0]\n",
    "        unscaled_feature = librosa.db_to_amplitude(unscaled_feature)\n",
    "        unscaled.append(unscaled_feature)\n",
    "    return np.array(unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def db_to_amplitude():\n",
    "#     librosa.db_to_amplitude()\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stft[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stft[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stft = MinMaxUnScaler(decoded_stft,X_test_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(X_test[5].reshape(257, 69), x_axis='time', y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.title(\"Generated Audio for Digit \" + str(y_test[n]))\n",
    "librosa.display.specshow(decoded_stft[5].reshape(257, 69), x_axis='time', y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256#900 #256 #500 #400\n",
    "abc = librosa.istft(decoded_stft[n],hop_length=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invserse STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISTFT(feature):\n",
    "    audios = []\n",
    "    for f in tqdm.tqdm(feature,desc=\"Appling inverse STFT ...\"):\n",
    "        audio = librosa.istft(f,hop_length=256)\n",
    "        audios.append(audio)\n",
    "    return np.array(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_istft = ISTFT(decoded_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 456 \n",
    "# n = 900 \n",
    "n = 776\n",
    "# n = 500 \n",
    "# n = 400\n",
    "\n",
    "abc = librosa.istft(decoded_stft[n],hop_length=256)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "time_values = np.linspace(0, len(abc)/22050, len(abc))\n",
    "plt.title(\"Generated Audio for Digit \" + str(y_test[n]))\n",
    "plt.plot(time_values,abc,color=\"purple\")\n",
    "plt.xlabel(\"Time (in seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "Audio(data=abc,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = librosa.istft(decoded_stft[n], hop_length=256)\n",
    "\n",
    "# Plot STFT\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot STFT\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"STFT\")\n",
    "plt.imshow(np.abs(decoded_stft[n]), aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot Audio Signal\n",
    "plt.subplot(1, 2, 2)\n",
    "time_values = np.linspace(0, len(abc) / 22050, len(abc))\n",
    "plt.title(\"Generated Audio for Digit \" + str(y_val[n]))\n",
    "plt.plot(time_values, abc, color=\"purple\")\n",
    "plt.xlabel(\"Time (in seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display Audio\n",
    "Audio(data=abc, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data=abc,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-VAE with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(1024, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch_size = K.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "y = Dense(256, activation='relu')(decoder_inputs)\n",
    "y = Dropout(0.3)(y)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "y = Dropout(0.3)(y)\n",
    "y = Dense(1024, activation='relu')(y)\n",
    "outputs = Dense(17733, activation='sigmoid')(y)\n",
    "\n",
    "# Define the encoder and decoder models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_inputs, outputs, name='decoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see encoder summary\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see decoder summary\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for VAE\n",
    "def vae_loss(inputs, x_decoded_mean):\n",
    "    recon_loss = original_dim * binary_crossentropy(inputs, x_decoded_mean)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(recon_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "dense_vae = Model(inputs, outputs, name='vae')\n",
    "dense_vae.compile(optimizer='adam', loss=vae_loss)\n",
    "dense_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestLossCallback(Callback):\n",
    "#     def __init__(self, test_data):\n",
    "#         self.test_data = test_data\n",
    "#         self.test_losses = []\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         test_loss = self.model.evaluate(self.test_data, self.test_data, verbose=0)\n",
    "#         print(f\"\\nTest Loss after Epoch {epoch + 1}: {test_loss}\")\n",
    "#         self.test_losses.append(test_loss)\n",
    "\n",
    "# test_loss_callback = TestLossCallback(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train the VAE\n",
    "\n",
    "# dense_vae_history = dense_vae.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_val, X_val),callbacks=[test_loss_callback])\n",
    "\n",
    "#  Train the VAE\n",
    "\n",
    "dense_vae_history = dense_vae.fit(X_train, X_train, epochs=100, batch_size=128, shuffle=True, validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(dense_vae_history.history[\"loss\"])\n",
    "plt.plot(dense_vae_history.history[\"val_loss\"])\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss plot for Variational AutoEncoder (with MLP)\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss = dense_vae.evaluate(X_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(7673.7411, 7667.3369, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_train)[0]\n",
    "y_train = [int(y) for y in y_train]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_train, s=3**2,cmap='viridis',alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_val)[0]\n",
    "y_val = [int(y) for y in y_val]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_val, s=3**2,cmap='viridis',alpha=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = encoder.predict(X_test)[0]\n",
    "y_test = [int(y) for y in y_test]\n",
    "plt.figure(figsize=(10, 9))\n",
    "plt.scatter(latent_space[:, 0], latent_space[:, 1], c=y_test, s=3**2,cmap='viridis',alpha=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Variable 1 ')\n",
    "plt.ylabel('Latent Variable 2 ')\n",
    "plt.title('2D Latent Space Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.output.write_wav(\"Val_set_900_1.wav\", abc, 22050)\n",
    "sf.write(\"Val_set_900_1.wav\", abc, 22050, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data=reduced_noise,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 5 # Number of samples to visualize\n",
    "# plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    librosa.display.specshow(X_val[i].reshape(257, 69), sr=22050, x_axis='time', y_axis='log',ax=ax[2,n, i + 1])\n",
    "    plt.imshow(X_test[i].reshape(69, 257))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_stft[i].reshape(69, 257))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = dense_vae.predict(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(X_test[5].reshape(257, 69), sr=22050, x_axis='time', y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(decoded_imgs[5].reshape(257, 69), sr=22050, x_axis='time', y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = librosa.istft(decoded_imgs[5].reshape(257, 69))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data=abc,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscale Min Max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(features):\n",
    "    scaled = []\n",
    "    min_max_values = []\n",
    "    for f in features:\n",
    "        min_val = np.min(f)\n",
    "        max_val = np.max(f)\n",
    "        f_normalized = (f - min_val) / (max_val - min_val)\n",
    "        min_max_values.append((min_val,max_val))\n",
    "        scaled.append(f_normalized)\n",
    "    return np.array(scaled),np.array(min_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , X_train_min_max  = MinMaxScaler(X_train_features)\n",
    "_ , X_val_min_max = MinMaxScaler(X_val_features)\n",
    "_ , X_test_min_max = MinMaxScaler(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxUnScaler(features, min_max_values):\n",
    "    unscaled = []\n",
    "    for f,min_max in zip(features,min_max_values):\n",
    "        unscaled_feature = (f * (min_max[1] - min_max[0])) + min_max[0]\n",
    "        unscaled.append(unscaled_feature)\n",
    "    return np.array(unscaled_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize reconstructed samples\n",
    "generated_audio = dense_vae.predict(X_val)\n",
    "n = 1 # Number of samples to visualize\n",
    "# plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(69, 257))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    librosa.display.specshow(X_val, sr=22050, x_axis='time', y_axis='log',ax=axs[i, j])\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(69, 257))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Lambda, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Convolutional VAE architecture\n",
    "input_shape = (1025,81,1)\n",
    "latent_dim = 2  # Size of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256,activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    # return the z mean\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim), mean=0.0, stddev=1.0)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim,))\n",
    "y = Dense(1025 * 81 * 64, activation='relu')(decoder_input)\n",
    "y = Reshape((1025, 81, 64))(y)\n",
    "# y = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(y)\n",
    "y = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(y)\n",
    "y = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = y\n",
    "decoder = Model(decoder_input,y)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = decoder(encoder(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for VAE\n",
    "def vae_loss(inputs, outputs):\n",
    "    xent_loss = K.sum(K.binary_crossentropy(inputs, outputs), axis=(1, 2, 3))\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vae = Model(inputs, outputs)\n",
    "cnn_vae.compile(optimizer='adam', loss=vae_loss)\n",
    "cnn_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE\n",
    "cnn_vae_history = cnn_vae.fit(X_train_features, X_train_features, epochs=2, batch_size=128, shuffle=True, validation_data=(X_val_features, X_val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
